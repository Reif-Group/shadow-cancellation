{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ab5ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pandas\n",
    "import numpy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fd4fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR='./'\n",
    "PERT_FRAC = 0.0\n",
    "OUT_FOLDER = str(PERT_FRAC).replace('.', '_')\n",
    "ROOT_FOLDER = 'rps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31685e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_leak_sections():\n",
    "    sections = [\n",
    "        [],\n",
    "        [],\n",
    "        [\n",
    "            'LeakWasteAC = sA mA fA hAk( + sC* ) fA*( hAk*( fA*( + ) ) ) @initial 0 nM',\n",
    "             'LeakWasteBA = sB mB fB hBr( + sA* ) fB*( hBr*( fB*( + ) ) ) @initial 0 nM',\n",
    "             'LeakWasteCB = sC mC fC hCj( + sB* ) fC*( hCj*( fC*( + ) ) ) @initial 0 nM'\n",
    "        ],\n",
    "        [\n",
    "            'macrostate LeakWasteCB = [LeakWasteCB]',\n",
    "             'macrostate LeakWasteBA = [LeakWasteBA]',\n",
    "             'macrostate LeakWasteAC = [LeakWasteAC]'\n",
    "        ],\n",
    "        [\n",
    "            'reaction [condensed    = 2e-7 /nM/s ] ProduceBCjCj + HelperCCj -> Cj + LeakWasteCB',\n",
    "             'reaction [condensed    = 2e-7 /nM/s ] ProduceABrBr + HelperBBr -> Br + LeakWasteBA',\n",
    "             'reaction [condensed    = 2e-7 /nM/s ] ProduceCAkAk + HelperAAk -> Ak + LeakWasteAC'\n",
    "        ]\n",
    "    ]\n",
    "    return sections\n",
    "\n",
    "def shadow_leak_sections():\n",
    "    sections = [\n",
    "        [],\n",
    "        [],\n",
    "        [\n",
    "            'sLeakWasteAC = hAkR( fAR mAR sAR + fAR( hAkR( fAR( + ) ) ) ) sCR* @initial 0 nM',\n",
    "             'sLeakWasteBA = hBrR( fBR mBR sBR + fBR( hBrR( fBR( + ) ) ) ) sAR* @initial 0 nM',\n",
    "             'sLeakWasteCB = hCjR( fCR mCR sCR + fCR( hCjR( fCR( + ) ) ) ) sBR* @initial 0 nM'\n",
    "        ],\n",
    "        [\n",
    "            'macrostate sLeakWasteAC = [sLeakWasteAC]',\n",
    "             'macrostate sLeakWasteBA = [sLeakWasteBA]',\n",
    "             'macrostate sLeakWasteCB = [sLeakWasteCB]'\n",
    "        ],\n",
    "        [\n",
    "            'reaction [condensed    = 2e-7 /nM/s ] sProduceBCjCj + sHelperCCj -> sCj + sLeakWasteCB',\n",
    "             'reaction [condensed   = 2e-7 /nM/s ] sProduceABrBr + sHelperBBr -> sBr + sLeakWasteBA',\n",
    "             'reaction [condensed   = 2e-7 /nM/s ] sProduceCAkAk + sHelperAAk -> sAk + sLeakWasteAC'\n",
    "        ]\n",
    "    ]\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47cedfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines(file):\n",
    "    with open(file, 'r') as fin:\n",
    "        lines = fin.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "    return lines\n",
    "\n",
    "def write_lines(lines, file):\n",
    "    with open(file, 'w') as fout:\n",
    "        for line in lines:\n",
    "            fout.write(line)\n",
    "            fout.write('\\n')\n",
    "            \n",
    "def eps_ub(d, frac):\n",
    "    l = [d + d*frac]\n",
    "    return round(random.choice(l), 9)\n",
    "\n",
    "def match_replace_rate_const(s, regex='([0-9]\\.[0-9]+)', frac=None):\n",
    "    x = re.search(regex, s)\n",
    "    if x is not None:\n",
    "        rep = str(eps_ub(float(x.group()), frac))\n",
    "        ret = re.sub(regex, rep, s)\n",
    "        return ret\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "def divide_sections(lines):\n",
    "    line_numbers = []\n",
    "    for i, line in enumerate(lines):\n",
    "        if '#' in line:\n",
    "            line_numbers.append(i)\n",
    "    line_numbers.append(len(lines))\n",
    "    sections = []\n",
    "    headers = []\n",
    "    for i in range(len(line_numbers)-1):\n",
    "        start = line_numbers[i]\n",
    "        end = line_numbers[i+1]\n",
    "        sections.append(lines[start+1:end])\n",
    "        headers.append(lines[start])\n",
    "    return headers, sections\n",
    "\n",
    "\n",
    "def merge(ofile, sfile, cfile=None):\n",
    "    olines = read_lines(ofile)\n",
    "    slines = read_lines(sfile)\n",
    "    \n",
    "    o_heds, o_secs = divide_sections(olines)\n",
    "    s_heds, s_secs = divide_sections(slines)\n",
    "    \n",
    "    o_leak_secs = original_leak_sections() \n",
    "    s_leak_secs = shadow_leak_sections()\n",
    "    \n",
    "    assert len(o_secs) == len(s_secs)\n",
    "    assert len(o_secs) == len(o_leak_secs)\n",
    "    \n",
    "    headers = o_heds\n",
    "    sections = [x[0] + x[1] + x[2] + x[3] for x in zip(o_secs, s_secs, o_leak_secs, s_leak_secs)]\n",
    "   \n",
    "    \n",
    "    if cfile is not None:\n",
    "        clines = read_lines(cfile)\n",
    "        c_heds, c_secs = divide_sections(clines)\n",
    "        assert len(c_secs) == len(o_secs)\n",
    "        sections = [x[0] + list(set(x[1]).difference(set(x[0]))) for x in zip(sections, c_secs)]\n",
    "    \n",
    "    return headers, sections\n",
    "\n",
    "def write_out(headers, sections, out=None, cancel=False):\n",
    "    lines = []\n",
    "    for h, s in zip(headers, sections):\n",
    "        lines += [h]\n",
    "        lines += s\n",
    "    subbed_lines = []\n",
    "    if cancel:\n",
    "        for line in lines:\n",
    "            if re.match(r'sCj = hCjR fCR mCR sCR @initial [0-9]+ nM', line) is not None:\n",
    "                subbed_lines += ['sCj = hCjR fCR mCR sCR @initial 0.5 nM']\n",
    "            elif re.match(r'sAk = hAkR fAR mAR sAR @initial [0-9]+ nM', line) is not None:\n",
    "                subbed_lines += ['sAk = hAkR fAR mAR sAR @initial 0.3 nM']\n",
    "            elif re.match(r'sBr = hBrR fBR mBR sBR @initial [0-9]+ nM', line) is not None:\n",
    "                subbed_lines += ['sBr = hBrR fBR mBR sBR @initial 0.2 nM']\n",
    "            else:\n",
    "                subbed_lines.append(line)\n",
    "                                \n",
    "        write_lines(subbed_lines, out)\n",
    "    else:\n",
    "        write_lines(lines, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf52424",
   "metadata": {},
   "source": [
    "# Add leaks to Original, Shadow, and Merge UnPerturbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c22fe3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = os.path.join(HOME_DIR, ROOT_FOLDER, OUT_FOLDER)\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.mkdir(OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47b62d44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ofile = os.path.join(HOME_DIR, ROOT_FOLDER, 'vanilla', 'main_enum.pil')\n",
    "sfile = os.path.join(HOME_DIR, ROOT_FOLDER, 'shadow_vanilla', 'main_enum.pil')\n",
    "cfile = os.path.join(HOME_DIR, ROOT_FOLDER, 'cancel', 'main_enum.pil')\n",
    "out_nocancel = os.path.join(OUT_DIR, 'orig_shadow_nocancel_enum.pil')\n",
    "out_cancel = os.path.join(OUT_DIR, 'orig_shadow_cancel_enum.pil')\n",
    "\n",
    "headers, sections = merge(ofile, sfile)\n",
    "write_out(headers, sections, out_nocancel)\n",
    "headers, sections = merge(ofile, sfile, cfile)\n",
    "write_out(headers, sections, out_cancel, cancel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22636cea",
   "metadata": {},
   "source": [
    "# Perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e157810",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = read_lines(os.path.join(HOME_DIR, ROOT_FOLDER, 'shadow_vanilla', 'main_enum.pil'))\n",
    "pert_lines = []\n",
    "for line in lines:\n",
    "    pert_lines.append(match_replace_rate_const(line, frac=PERT_FRAC))\n",
    "write_lines(pert_lines, os.path.join(HOME_DIR, ROOT_FOLDER, 'shadow_vanilla', f'main_pert-{PERT_FRAC}_enum.pil'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf7098",
   "metadata": {},
   "source": [
    "# Add leaks to Original, Shadow, and Perturbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a931d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ofile = os.path.join(HOME_DIR, ROOT_FOLDER, 'vanilla', 'main_enum.pil')\n",
    "sfile = os.path.join(HOME_DIR, ROOT_FOLDER, 'shadow_vanilla', f'main_pert-{PERT_FRAC}_enum.pil')\n",
    "cfile = os.path.join(HOME_DIR, ROOT_FOLDER, 'cancel', 'main_enum.pil')\n",
    "out_nocancel = os.path.join(OUT_DIR, 'orig_shadow_pert_nocancel_enum.pil')\n",
    "out_cancel = os.path.join(OUT_DIR, 'orig_shadow_pert_cancel_enum.pil')\n",
    "\n",
    "headers, sections = merge(ofile, sfile)\n",
    "write_out(headers, sections, out_nocancel)\n",
    "headers, sections = merge(ofile, sfile, cfile)\n",
    "write_out(headers, sections, out_cancel, cancel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932529b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
