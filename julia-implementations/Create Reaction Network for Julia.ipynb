{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29eea16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f895e7",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2467dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lines(filepath):\n",
    "    lines = []\n",
    "    try:\n",
    "        with open(filepath, 'r') as fin:\n",
    "            lines = fin.readlines()\n",
    "            lines = [line.strip() for line in lines]\n",
    "    except:\n",
    "        return lines\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e02ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reaction(reactants, products, rate_constant):\n",
    "    reaction = {\n",
    "        'rate_constant': rate_constant,\n",
    "        'reactants': reactants,\n",
    "        'products': products\n",
    "    }\n",
    "    return reaction\n",
    "\n",
    "\n",
    "def print_reaction(reaction):\n",
    "    reactants = ' + '.join(reaction['reactants'])\n",
    "    products = ' + '.join(reaction['products'])\n",
    "    rate_constant = reaction['rate_constant']\n",
    "    s = f'{rate_constant}, {reactants} --> {products}'\n",
    "    return s\n",
    "\n",
    "    \n",
    "def convert_autocatalytic_to_catalytic(rs, ps, rate_constant='k', N=3):\n",
    "    reactions = []\n",
    "    for i in range(N):\n",
    "        reactants = []\n",
    "        products = []\n",
    "        for j in range(len(rs)):\n",
    "            reactants.append(rs[j] + str(i))\n",
    "        for j in range(len(ps)):\n",
    "            products.append(ps[j] + str((i+j)%N))\n",
    "        reaction = build_reaction(reactants, products, rate_constant)\n",
    "        reactions.append(reaction)\n",
    "    return reactions\n",
    "\n",
    "\n",
    "def reaction_type(reaction):\n",
    "    reactants = reaction['reactants']\n",
    "    if len(reactants) == 1:\n",
    "        return 'uni'\n",
    "    if len(reactants) == 2:\n",
    "        return 'bi'\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f271df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('k/infConc, x0 + Gx01 --> Ix0',\n",
       " {'rate_constant': 'k/infConc',\n",
       "  'reactants': ['x0', 'Gx01'],\n",
       "  'products': ['Ix0']})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_annihilation_reactions(dna_reaction={}, infRate='infRate', leak='leak', shadow='shadow', shadow_prefix='s'):\n",
    "    reactants = dna_reaction['reactants']\n",
    "    k = dna_reaction['rate_constant']\n",
    "    products = dna_reaction['products']\n",
    "    \n",
    "    annihilative_reactants = [r for r in reactants if re.match(r'^G|^L|^s', r) is None]\n",
    "    annihilative_products = [p for p in products if re.match(r'^G|^L|^s', p) is None]\n",
    "    annihilative = set(annihilative_reactants + annihilative_products)\n",
    "    ann_reactions = []\n",
    "    for sp in annihilative:\n",
    "        ann_reactions += [build_reaction([sp, shadow_prefix+sp], ['waste'], f'{leak}*{shadow}*{infRate}')]\n",
    "    return ann_reactions\n",
    "\n",
    "def get_leak_reaction_or_none(dna_reaction={}, leak_rate='leak_rate', leak_flag='leak'):\n",
    "    reactants = dna_reaction['reactants']\n",
    "    k = dna_reaction['rate_constant']\n",
    "    products = dna_reaction['products']\n",
    "    leaky = None\n",
    "    \n",
    "    # No leak if it is like a linker reaction\n",
    "    if (len(reactants) < 2) or (re.match('^G|^L', reactants[1])==None):\n",
    "        return leaky\n",
    "    k = f'{leak_flag}*{leak_rate}'\n",
    "    reactants = reactants[1:]\n",
    "    leaky = build_reaction(reactants, products, k)\n",
    "    return leaky\n",
    "    \n",
    "    \n",
    "def get_shadow_reaction(dna_reaction={}, shadow='shadow', shadow_prefix='s'):\n",
    "    reactants = dna_reaction['reactants']\n",
    "    k = dna_reaction['rate_constant']\n",
    "    products = dna_reaction['products']\n",
    "    reactants = [shadow_prefix + r for r in reactants]\n",
    "    products = [shadow_prefix + p for p in products]\n",
    "    k = f'{shadow}*{k}'\n",
    "    shadow = build_reaction(reactants, products, k)\n",
    "    return shadow\n",
    "\n",
    "\n",
    "def dna_implementation(reaction={}, gate_prefix='G', \n",
    "                       linker_prefix='L', intermediate_prefix='I',\n",
    "                      infRate='infRate', infConc='infConc',\n",
    "                      bimolRate='bimolRate'):\n",
    "    dna_reactions = []\n",
    "    if reaction_type(reaction) == 'uni':\n",
    "        reactants = reaction['reactants']\n",
    "        k = reaction['rate_constant']\n",
    "        products = reaction['products']\n",
    "        try:\n",
    "            xi = reactants[0]\n",
    "            species = re.findall(r'^[a-zA-Z]+', xi)[0]\n",
    "            index = re.findall(r'[0-9]+', xi)[0]\n",
    "        except:\n",
    "            print('ERROR! INVALID Species Name')\n",
    "            return []\n",
    "        \n",
    "        gate_species_1 = ''.join([gate_prefix, species, index, '1'])\n",
    "        temp = ''.join([intermediate_prefix, xi])\n",
    "        gate_species_2 = ''.join([gate_prefix, species, index, '2'])\n",
    "        dna_reactions += [build_reaction(reactants + [gate_species_1], [temp], f'{k}/{infConc}')]\n",
    "        dna_reactions += [build_reaction([temp, gate_species_2], products, infRate)]\n",
    "        \n",
    "    \n",
    "    if reaction_type(reaction) == 'bi':\n",
    "        reactants = reaction['reactants']\n",
    "        k = reaction['rate_constant']\n",
    "        products = reaction['products']\n",
    "        try:\n",
    "            regular_reactant = reactants[0]\n",
    "            linker_reactant = reactants[1]\n",
    "            first_product = products[0]\n",
    "            first_product_species = re.findall(r'^[a-zA-Z]+', first_product)[0]\n",
    "            \n",
    "            first_product_index = re.findall(r'[0-9]+', first_product)[0]\n",
    "            linker_species = re.findall(r'^[a-zA-Z]+', linker_reactant)[0]\n",
    "            linker_index = re.findall(r'[0-9]+', linker_reactant)[0]\n",
    "            linker_gate = ''.join([linker_prefix, linker_species, linker_index])\n",
    "            \n",
    "        except:\n",
    "            print('ERROR! INVALID Species Name')\n",
    "            return []\n",
    "        \n",
    "        temp = ''.join([intermediate_prefix, first_product_species, first_product_index])\n",
    "        dna_reactions += [build_reaction([regular_reactant, linker_gate], [temp], bimolRate)]\n",
    "        gate_species = ''.join([gate_prefix, first_product_species, first_product_index])\n",
    "        dna_reactions += [build_reaction([temp, gate_species], products, infRate)]\n",
    "        # Linker steps\n",
    "        dna_reactions += [build_reaction([linker_gate], [linker_reactant], infRate)]\n",
    "        dna_reactions += [build_reaction([linker_reactant], [linker_gate], infRate)]\n",
    "                              \n",
    "    return dna_reactions\n",
    "reactions = convert_autocatalytic_to_catalytic(['x'], ['y', 'y'])\n",
    "print_reaction(dna_implementation(reactions[0])[0]), dna_implementation(reactions[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f246f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "339ca45c",
   "metadata": {},
   "source": [
    "#### Create a reaction network in Julia with the above network. Then print the species array and then get back down here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02631efc",
   "metadata": {},
   "source": [
    "## Concentrations assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e493fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "def assign_concentrations(species, regular_conc='approp', infConc='infConc', zero='0.0'):\n",
    "    concentrations = []\n",
    "    for sp in species:\n",
    "        if re.match(r'^G|^sG', sp) is not None:\n",
    "            concentrations.append(infConc)\n",
    "            continue\n",
    "        if re.match(r'^I|^sI', sp) is not None:\n",
    "            concentrations.append(zero)\n",
    "            continue\n",
    "        # Note that we already set the shadow gate concentrations\n",
    "        if re.match(r'^s', sp) is not None:\n",
    "            concentrations.append(zero)\n",
    "            continue\n",
    "        if re.match(r'^waste', sp) is not None:\n",
    "            concentrations.append(zero)\n",
    "            continue\n",
    "        concentrations.append(f'{sp}:{regular_conc}')\n",
    "    return concentrations\n",
    "\n",
    "def process_species(species):\n",
    "    concs = assign_concentrations(species)\n",
    "    for iter, (s, c) in enumerate(zip(species, concs)):\n",
    "        print(iter+1, s, c)\n",
    "    return concs\n",
    "\n",
    "def pprint_list(arr, limit=5):\n",
    "    sz = len(arr)\n",
    "    index = 0\n",
    "    print('[')\n",
    "    while index < sz:\n",
    "        j = 0\n",
    "        s = ''\n",
    "        while j < limit:\n",
    "            if index+j >= sz:\n",
    "                index = index + j\n",
    "                break\n",
    "            s += str(arr[index+j]) + ', '\n",
    "            j += 1\n",
    "        index += limit\n",
    "        print(s)\n",
    "    print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d24b8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reaction_network(filepath=None, section_split_token='|', sub_section_split=','):\n",
    "    \"\"\"Given a file containing one reaction per line according to the below spec\n",
    "    this function builds a reaction network and assigns concentrations\n",
    "    wherever applicable for the Julia implementation.\n",
    "    \n",
    "    Author: Rajiv Nagipogu\n",
    "    \n",
    "    Reaction Spec(don't worry about the spaces in between)\n",
    "    rate | comma separated reactants | comma separated products\n",
    "    \"\"\"\n",
    "    line = 'k | x, | x, x,'\n",
    "    \n",
    "    def __clean(token):\n",
    "        token = token.strip()\n",
    "        token = token.replace(r'[^a-zA-Z0-9]', '')\n",
    "        return token\n",
    "    \n",
    "    def __parse_line(line):\n",
    "        sections = line.split(section_split_token)\n",
    "        sections = [__clean(section) for section in sections]\n",
    "        assert(len(sections) == 3) # must contain only 3 sections!\n",
    "        k, rs, ps = sections\n",
    "        rs = rs.split(sub_section_split)\n",
    "        rs = [__clean(r) for r in rs]\n",
    "        rs = [r for r in rs if r != '']\n",
    "        ps = ps.split(sub_section_split)\n",
    "        ps = [__clean(p) for p in ps]\n",
    "        ps = [p for p in ps if p != '']\n",
    "        \n",
    "        return k, rs, ps\n",
    "    \n",
    "    reactions = []\n",
    "    lines = read_lines(filepath)\n",
    "    for line in lines:\n",
    "    \n",
    "        k, rs, ps = __parse_line(line)\n",
    "\n",
    "        reaction = build_reaction(rs, ps, k)\n",
    "        reactions.append(reaction)\n",
    "\n",
    "    return reactions\n",
    "\n",
    "def main(filepath, N=3):\n",
    "    \"\"\"\n",
    "    reactions(dict): {'rate_constant': 'k', 'reactants': ['x'], 'products': ['x', 'x']}\n",
    "    N: Used when converting autocatalytic to catalytic reaction step\n",
    "    \"\"\"\n",
    "\n",
    "    assert os.path.exists(filepath), \"File doesn't exist\"\n",
    "    reactions = build_reaction_network(filepath)\n",
    "    \n",
    "    all_reactions = []\n",
    "    \n",
    "    for reaction in reactions:\n",
    "        \n",
    "        # All catalytic reactions for a given autocatalytic\n",
    "        cats = convert_autocatalytic_to_catalytic(reaction['reactants'], \n",
    "                                                           reaction['products'], \n",
    "                                                           reaction['rate_constant'], N)\n",
    "        for cat_reaction in cats:\n",
    "            \n",
    "            # DNA reactions for a given catalytic reaction\n",
    "            dna_reactions = dna_implementation(cat_reaction)\n",
    "            \n",
    "            for dna_reaction in dna_reactions:\n",
    "                # Add the original dna reaction\n",
    "                s = print_reaction(dna_reaction)\n",
    "                if s not in all_reactions: all_reactions.append(s)\n",
    "                # Add the shadow reaction\n",
    "                s = print_reaction(get_shadow_reaction(dna_reaction))\n",
    "                if s not in all_reactions: all_reactions.append(s)\n",
    "                # Add leak for both the shadow and regular reaction if any\n",
    "                leak = get_leak_reaction_or_none(dna_reaction)\n",
    "                if leak is not None:\n",
    "                    s = print_reaction(leak)\n",
    "                    if s not in all_reactions: all_reactions.append(s)\n",
    "                    s = print_reaction(get_shadow_reaction(leak))\n",
    "                    if s not in all_reactions: all_reactions.append(s)\n",
    "                # Add annihilation reactions\n",
    "                ann_reactions = add_annihilation_reactions(dna_reaction)\n",
    "                for ann_reaction in ann_reactions:\n",
    "                    s = print_reaction(ann_reaction)\n",
    "                    if s not in all_reactions: all_reactions.append(s)\n",
    "    print(\"=========== Reactions ===============\")\n",
    "    for r in all_reactions:\n",
    "        print(r)                \n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6349b153",
   "metadata": {},
   "source": [
    "## Print Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec02c418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Reactions ===============\n",
      "bimolRate, x0 + Ly0 --> Iy0\n",
      "shadow*bimolRate, sx0 + sLy0 --> sIy0\n",
      "leak*leak_rate, Ly0 --> Iy0\n",
      "shadow*leak*leak_rate, sLy0 --> sIy0\n",
      "leak*shadow*infRate, x0 + sx0 --> waste\n",
      "leak*shadow*infRate, Iy0 + sIy0 --> waste\n",
      "infRate, Iy0 + Gy0 --> y0 + y1\n",
      "shadow*infRate, sIy0 + sGy0 --> sy0 + sy1\n",
      "leak*leak_rate, Gy0 --> y0 + y1\n",
      "shadow*leak*leak_rate, sGy0 --> sy0 + sy1\n",
      "leak*shadow*infRate, y1 + sy1 --> waste\n",
      "leak*shadow*infRate, y0 + sy0 --> waste\n",
      "infRate, Ly0 --> y0\n",
      "shadow*infRate, sLy0 --> sy0\n",
      "infRate, y0 --> Ly0\n",
      "shadow*infRate, sy0 --> sLy0\n",
      "bimolRate, x1 + Ly1 --> Iy1\n",
      "shadow*bimolRate, sx1 + sLy1 --> sIy1\n",
      "leak*leak_rate, Ly1 --> Iy1\n",
      "shadow*leak*leak_rate, sLy1 --> sIy1\n",
      "leak*shadow*infRate, x1 + sx1 --> waste\n",
      "leak*shadow*infRate, Iy1 + sIy1 --> waste\n",
      "infRate, Iy1 + Gy1 --> y1 + y2\n",
      "shadow*infRate, sIy1 + sGy1 --> sy1 + sy2\n",
      "leak*leak_rate, Gy1 --> y1 + y2\n",
      "shadow*leak*leak_rate, sGy1 --> sy1 + sy2\n",
      "leak*shadow*infRate, y2 + sy2 --> waste\n",
      "infRate, Ly1 --> y1\n",
      "shadow*infRate, sLy1 --> sy1\n",
      "infRate, y1 --> Ly1\n",
      "shadow*infRate, sy1 --> sLy1\n",
      "bimolRate, x2 + Ly2 --> Iy2\n",
      "shadow*bimolRate, sx2 + sLy2 --> sIy2\n",
      "leak*leak_rate, Ly2 --> Iy2\n",
      "shadow*leak*leak_rate, sLy2 --> sIy2\n",
      "leak*shadow*infRate, x2 + sx2 --> waste\n",
      "leak*shadow*infRate, Iy2 + sIy2 --> waste\n",
      "infRate, Iy2 + Gy2 --> y2 + y0\n",
      "shadow*infRate, sIy2 + sGy2 --> sy2 + sy0\n",
      "leak*leak_rate, Gy2 --> y2 + y0\n",
      "shadow*leak*leak_rate, sGy2 --> sy2 + sy0\n",
      "infRate, Ly2 --> y2\n",
      "shadow*infRate, sLy2 --> sy2\n",
      "infRate, y2 --> Ly2\n",
      "shadow*infRate, sy2 --> sLy2\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "all_reactions = main('bimolecular.spec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11333442",
   "metadata": {},
   "source": [
    "## Put this reaction Network in Julia and Get species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc7c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = ['x0(t)','Ly0(t)','Iy0(t)','sx0(t)','sLy0(t)','sIy0(t)','waste(t)','Gy0(t)','y0(t)','y1(t)','sGy0(t)','sy0(t)','sy1(t)','x1(t)','Ly1(t)','Iy1(t)','sx1(t)','sLy1(t)','sIy1(t)','Gy1(t)','y2(t)','sGy1(t)','sy2(t)','x2(t)','Ly2(t)','Iy2(t)','sx2(t)','sLy2(t)','sIy2(t)','Gy2(t)','sGy2(t)',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8d50eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 x0(t) x0(t):approp\n",
      "2 Ly0(t) Ly0(t):approp\n",
      "3 Iy0(t) 0.0\n",
      "4 sx0(t) 0.0\n",
      "5 sLy0(t) 0.0\n",
      "6 sIy0(t) 0.0\n",
      "7 waste(t) 0.0\n",
      "8 Gy0(t) infConc\n",
      "9 y0(t) y0(t):approp\n",
      "10 y1(t) y1(t):approp\n",
      "11 sGy0(t) infConc\n",
      "12 sy0(t) 0.0\n",
      "13 sy1(t) 0.0\n",
      "14 x1(t) x1(t):approp\n",
      "15 Ly1(t) Ly1(t):approp\n",
      "16 Iy1(t) 0.0\n",
      "17 sx1(t) 0.0\n",
      "18 sLy1(t) 0.0\n",
      "19 sIy1(t) 0.0\n",
      "20 Gy1(t) infConc\n",
      "21 y2(t) y2(t):approp\n",
      "22 sGy1(t) infConc\n",
      "23 sy2(t) 0.0\n",
      "24 x2(t) x2(t):approp\n",
      "25 Ly2(t) Ly2(t):approp\n",
      "26 Iy2(t) 0.0\n",
      "27 sx2(t) 0.0\n",
      "28 sLy2(t) 0.0\n",
      "29 sIy2(t) 0.0\n",
      "30 Gy2(t) infConc\n",
      "31 sGy2(t) infConc\n",
      "================ Copy this back ================\n",
      "[\n",
      "x0(t):approp, Ly0(t):approp, 0.0, 0.0, 0.0, \n",
      "0.0, 0.0, infConc, y0(t):approp, y1(t):approp, \n",
      "infConc, 0.0, 0.0, x1(t):approp, Ly1(t):approp, \n",
      "0.0, 0.0, 0.0, 0.0, infConc, \n",
      "y2(t):approp, infConc, 0.0, x2(t):approp, Ly2(t):approp, \n",
      "0.0, 0.0, 0.0, 0.0, infConc, \n",
      "infConc, \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "arr = process_species(species)\n",
    "print(\"================ Copy this back ================\")\n",
    "pprint_list(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a38a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
